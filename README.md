# CBS Media Monitoring Dashboard

Modernizing the CBS article-linking pipeline by replacing legacy lexical heuristics with a high-precision Dutch semantic vector space model.

**[Data Access (OneDrive)](https://amsuni-my.sharepoint.com/:f:/g/personal/rezi_getsadze_student_uva_nl/IgCfw2IuixE6Q5sF5awolVqIAUL91e2MVvGQp3EB6e9-xO0?e=bZj43V):** Raw article corpus and CSVs. The OneDrive repository contains the following raw and reconstructed datasets:

* **`c_*.csv`**: Thousands of individual raw news articles (Children) collected from external media.
* **`c_*_output.csv`**: Legacy prediction outputs for each child article, containing ranked match candidates and confidence scores for each.
* **`p_*.csv`**: Individual CBS publication data (Parents) used as the ground truth for reports.
* **`all_parents.csv`**: The initial aggregate repository of official CBS reports (not actually "all," some were missing and in separate parent csvs).
These files were generated by our file-stitching pipeline to resolve missing data and metadata gaps in the legacy folder:
* **`full_children.csv`**: A unified corpus containing every news article with its full raw text and metadata.
* **`full_parents.csv`**: A complete aggregate of all CBS reports, including those missing from the original `all_parents.csv`.
* **`full_matches.csv`**: The master list of all verified parent-child links used to generate training labels.

The main model (Phase 2 Overhaul) is a ground-up reconstruction of the system designed to eliminate "lazy" matching. It features a file-stitching pipeline to unify 350,000+ files and uses 300-dimensional spaCy Dutch embeddings. By implementing Hard Negative logic (pairing unrelated same-day articles), it breaks the original model's dependency on publication dates, achieving a major jump in precision.

### Core Production
| File | Purpose |
| :--- | :--- |
| **`rf_models_reconstructed.ipynb`** | **Main entry point.** Runs A/B tests and Error Analysis. |
| **`trainset_reconstructed.csv`** | Re-engineered master training set (300-d vectors + Hard Negatives). |
| **`new_preprocess.ipynb`** | The engine. Stitches 350k+ raw files and calculates spaCy vectors. |
| **`model_rf_fixed.pkl`** | Serialized production model (Model B) for dashboard integration. |

### Extended Modules
* **`network_graph.ipynb`**: Interactive relationship map (generates `family_cluster.html`).
* **`model_C.ipynb`**: Advanced neural retrieval prototype (BM25 + Cross-Encoders).
* **`lib/`**: [RACHNA: INSERT REACT FRONTEND REPO/FILES HERE].
* **`/Legacy/`**: Original CBS baseline scripts, functions, and taxonomy files preserved for comparison.
* **`/Old Preprocessing/`**: Audit trail containing Phase 1 scripts that identified Jaccard metric errors and English-stemming bias in the original data.

### Environment Setup
```bash
pip install -r requirements.txt
python -m spacy download nl_core_news_lg
```
## Model Comparison

| Model | Approach | Status | Key Improvements |
| :--- | :--- | :--- | :--- |
| **Original Model (A0)** | Initial Baseline | **Flawed** | Legacy code provided by CBS; contained Jaccard metric errors and English-stemming bias. |
| **Model A1** | Fixed Baseline | **Phase 1 Fix** | Corrected the asymmetric metric logic and fixed Dutch stemming on the provided masterlist. |
| **Model B1** | Initial Semantic | **Phase 1 Fix** | Replaced character-matching with spaCy vectors to solve "lexical blindness" on audited data. |
| **Model A2** | Reconstructed Lexical | **Phase 2 Overhaul** | Legacy features applied to the full 350k corpus with 1:1 Hard Negative sampling to break date-bias. |
| **Model B2** | **Production Semantic** | **Phase 2 Overhaul** | Final production model. Combines Dutch embeddings with Hard Negative mining for maximum precision. |

### Model C - Advanced Neural Retrieval & Reranking

Model C introduces a two-stage retrieval pipeline designed for high-recall scenarios where a standard classifier might miss nuanced semantic links.

**Implemented components:**
- **First-Stage Retrieval (BM25)** - Efficiently filters the 350k+ article corpus to generate a shortlist of candidates for each CBS report.
- **Second-Stage Reranking (Neural Cross-Encoder)** - Utilizes a Transformer-based Cross-Encoder to perform deep semantic comparison between the CBS report and each candidate.
  - Implements **chunking logic** to handle long-form reports without losing contextual information.
- **Margin-Based Decision Logic** - Calculates a **Margin Score** (the difference between the top-ranked candidate and the runner-up).
  - **High Margin:** Confidence is high; the top match is distinctly better than alternatives (**AUTO_POSITIVE**).
  - **Low Margin:** The model is uncertain between two or more candidates; the pair is flagged for **REVIEW**.

**Output & Artefacts:**
- **Notebook:** `model_C.ipynb` contains the full retrieval and reranking logic.
- **Per-Article Results:** Prediction outputs are saved as individual CSVs (e.g., `model_c_parent_1200833_margin_2.0.csv`).
- **File Schema:**
  - `rank`: The position of the candidate article in the reranked list.
  - `score`: The raw logit output from the Cross-Encoder.
  - `margin_top1_top2`: The numerical distance between the #1 and #2 match.
  - `decision`: Automated label based on the margin threshold (AUTO_POSITIVE, REVIEW, or IGNORE).

**Planned Extensions:**
- **ColBERT (Late Interaction):** Moving from BM25 to neural retrieval for the first stage to capture semantic matches that share no exact keywords.

### `/Legacy/`
The baseline environment as originally received. These files are preserved for comparison.

* **`final_project_functions.py` / `preprocessing_project_functions.py`**: Legacy scripts containing the different Jaccard implementation.
* **`trainset2.py` / `final_trainset.csv`**: The original training generation logic and the resulting biased dataset.
* **`rf_training_eval_step.ipynb`**: The original notebook used to report the baseline 93% accuracy.
* **`taxonomie_df.csv`**: The master list of 5,010 categories used for legacy keyword lookup.

### `/old_preprocessing/` (Phase 1 Audit)
This folder contains the technical audit that proved the original system was link-matching based on date rather than text.

* **`fixed_preprocess.ipynb`**: The initial fix script that re-calculated similarity scores for the existing masterlist using spaCy (still based on provided trainset).
* **`match_verification.ipynb`**: A manual audit tool that compares raw data titles to verify that trainset contains positives.
* **`final_balanced_training_set.csv`**: The first iteration of a sanitized training set, used for Models A1 and B1.

## Network Graph - `network_graph.ipynb`
* **Global View:** Displays macroscopic clustering of the entire CBS media ecosystem.
* **Family Clusters:** Provides a microscopic view of individual articles and their related reports.
* **Logic:** Nodes are color-coded by confidence (Green > 0.88, Yellow 0.5-0.88). It uses a Barnes-Hut physics engine to allow analysts to physically manipulate and explore connections between reports.

## Reproducibility & Environment
* **Python Version:** 3.13
* **Random Seed:** `random_state=42` used across all notebook initializations where relevant (the answer to life, the universe, and everything).
* **Dependencies:** Refer to `requirements.txt`.
* **Hardware Note:** Preprocessing 350k+ files via `new_preprocess.ipynb` is memory-intensive. For the sanity of your hardware, utilize the pre-generated `trainset_reconstructed.csv` to bypass the stitching phase.
