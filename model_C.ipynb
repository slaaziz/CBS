{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d90fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob \n",
    "\n",
    "\n",
    "DATA_DIR = os.path.expanduser(\"~/Desktop/CBS code/data\")\n",
    "PARENTS_FILE = os.path.join(DATA_DIR, \"all_parents.csv\")\n",
    "MATCH_FILE = \"trainset_reconstructed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a604978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent ID: 674230\n",
      "True child ID (from legacy high-conf): 674464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>match</th>\n",
       "      <th>title_sim_dutch</th>\n",
       "      <th>content_sim_dutch</th>\n",
       "      <th>title_sim_legacy</th>\n",
       "      <th>content_sim_legacy</th>\n",
       "      <th>days_diff</th>\n",
       "      <th>date_binary</th>\n",
       "      <th>legacy_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>674464</td>\n",
       "      <td>674230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.891758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085439</td>\n",
       "      <td>0.165046</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>674464</td>\n",
       "      <td>674045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.891758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085439</td>\n",
       "      <td>0.402882</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1429753</td>\n",
       "      <td>1428246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547830</td>\n",
       "      <td>0.882689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076449</td>\n",
       "      <td>1.019444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1047901</td>\n",
       "      <td>1047816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164229</td>\n",
       "      <td>0.739795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1258730</td>\n",
       "      <td>1258434</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273474</td>\n",
       "      <td>0.972838</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.346847</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    child_id  parent_id  match  title_sim_dutch  content_sim_dutch  \\\n",
       "0     674464     674230      1         0.000000           0.891758   \n",
       "2     674464     674045      1         0.000000           0.891758   \n",
       "18   1429753    1428246      1         0.547830           0.882689   \n",
       "28   1047901    1047816      1         0.164229           0.739795   \n",
       "54   1258730    1258434      1         0.273474           0.972838   \n",
       "\n",
       "    title_sim_legacy  content_sim_legacy  days_diff  date_binary  \\\n",
       "0           0.000000            0.085439   0.165046            1   \n",
       "2           0.000000            0.085439   0.402882            1   \n",
       "18          0.000000            0.076449   1.019444            1   \n",
       "28          0.000000            0.207792   0.002778            1   \n",
       "54          0.117647            0.346847   0.385417            1   \n",
       "\n",
       "    legacy_confidence  \n",
       "0              0.8943  \n",
       "2              0.8943  \n",
       "18             0.9804  \n",
       "28             0.9907  \n",
       "54             0.9853  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = pd.read_csv(MATCH_FILE)\n",
    "\n",
    "# rename this column so we don't confuse it with model scores\n",
    "matches = matches.rename(columns={\"%\": \"legacy_confidence\"})\n",
    "\n",
    "matches[\"parent_id\"] = matches[\"parent_id\"].astype(int)\n",
    "matches[\"child_id\"]  = matches[\"child_id\"].astype(int)\n",
    "matches[\"match\"]     = matches[\"match\"].astype(int)\n",
    "matches[\"legacy_confidence\"] = pd.to_numeric(matches[\"legacy_confidence\"], errors=\"coerce\")\n",
    "\n",
    "HIGH_CONF = 0.88\n",
    "positives = matches[(matches[\"match\"] == 1) & (matches[\"legacy_confidence\"] >= HIGH_CONF)]\n",
    "\n",
    "row = positives.iloc[0]\n",
    "parent_id = int(row[\"parent_id\"])\n",
    "true_child_id = int(row[\"child_id\"])\n",
    "\n",
    "print(\"Parent ID:\", parent_id)\n",
    "print(\"True child ID (from legacy high-conf):\", true_child_id)\n",
    "\n",
    "positives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077fd784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent columns: ['BT_TT', 'Gebruik_UF', '_version_', 'authors', 'authors_string', 'circulation', 'content', 'content_no_numbers', 'content_without_stopwords', 'copyright', 'datasource_key', 'datasource_theme', 'datasource_theme_string', 'datasource_title', 'datasource_type_key', 'datasource_type_title', 'departments', 'departments_string', 'document_key', 'duration', 'edition', 'edition_string', 'embargo', 'external_id', 'external_parent_id', 'first_paragraph_without_stopwords', 'found_synonyms', 'gatekeeper_key', 'graphic', 'id', 'import_id', 'insert_date', 'insert_date_date', 'kamerstuk_reference_number', 'kamerstuk_reference_number_string', 'link', 'media_value', 'medium', 'medium_category', 'medium_category_string', 'medium_string', 'medium_subcategory', 'medium_subcategory_string', 'mig_page', 'mig_title', 'mom_impact_score', 'page', 'parent_numbers', 'phenomenon', 'press_conference', 'press_conference_string', 'program', 'program_string', 'publication', 'publication_calendar', 'publication_issue', 'publication_issue_string', 'publication_string', 'publish_date', 'publish_date_date', 'publish_day', 'publish_hour', 'publish_minute', 'publish_month', 'publish_week', 'publish_weekday', 'publish_year', 'publisher', 'publisher_string', 'reach', 'regional_data', 'related_children', 'related_parents', 'related_parents_string', 'reproductions', 'section', 'section_string', 'series', 'series_string', 'social_profile_image', 'source', 'source_string', 'spokesmen', 'spokesmen_string', 'subject', 'subject_string', 'surface', 'tags', 'tags_string', 'taxonomies', 'taxonomies_string', 'themes', 'themes_string', 'title', 'title_without_stopwords', 'video', 'word_count', 'version', 'author_types', 'author_type_string', 'field_value_ids', 'page_string', 'taxonomy_id']\n"
     ]
    }
   ],
   "source": [
    "parents = pd.read_csv(PARENTS_FILE)\n",
    "parents = parents.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
    "\n",
    "print(\"Parent columns:\", list(parents.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ffc43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/souadlaaziz/Desktop/CBS code/data/c_1298147.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_689286.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_932753.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1280708.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1347257.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1205716.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1301202.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1400435.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1024774.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1377394.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, \"c_*.csv\"))\n",
    "\n",
    "child_files = [\n",
    "    f for f in all_files\n",
    "    if \"_output\" not in os.path.basename(f)\n",
    "]\n",
    "\n",
    "child_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c3d3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found parent rows: 1\n",
      "bronneninventarisatie in de wereld van de internationale statistiek bestaan er vele verschillende leveranciers van allerlei soorten data. het vinden van de juiste bron voor het beantwoorden van een bepaalde vraag kan daarbij uitdagend zijn, zeker wanneer diverse bronnen verschillende cijfers lijken te rapporteren over hetzelfde onderwerp.\n",
      "\n",
      "een voorbeeld betreft data over innovatie. zowel de world economic forum (wef) als de world intellectual property organization (wipo) rangschikken landen jaar\n"
     ]
    }
   ],
   "source": [
    "# column name that contains the parent ID\n",
    "PARENT_ID_COL = \"id\"\n",
    "\n",
    "# select the correct parent row\n",
    "parent_row = parents[parents[PARENT_ID_COL] == parent_id]\n",
    "\n",
    "print(\"Found parent rows:\", len(parent_row))\n",
    "\n",
    "# sanity check: show the row (optional)\n",
    "parent_row.iloc[0]\n",
    "\n",
    "# choose ONLY meaningful text columns for retrieval\n",
    "TEXT_COLS = [\n",
    "    \"title\",\n",
    "    \"content\",\n",
    "    \"first_paragraph_without_stopwords\",\n",
    "    \"tags_string\",\n",
    "    \"themes_string\",\n",
    "    \"subject_string\",\n",
    "]\n",
    "\n",
    "# build the parent query text\n",
    "parent_text = \" \".join(\n",
    "    str(parent_row.iloc[0][col])\n",
    "    for col in TEXT_COLS\n",
    "    if col in parent_row.columns and pd.notna(parent_row.iloc[0][col])\n",
    ").lower()\n",
    "\n",
    "# preview to make sure it looks sane\n",
    "print(parent_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf45bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num child files: 174190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/souadlaaziz/Desktop/CBS code/data/c_1298147.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_689286.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_932753.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1280708.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1347257.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1205716.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1301202.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1400435.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1024774.csv',\n",
       " '/Users/souadlaaziz/Desktop/CBS code/data/c_1377394.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = glob.glob(os.path.join(DATA_DIR, \"c_*.csv\"))\n",
    "\n",
    "child_files = [\n",
    "    f for f in all_files\n",
    "    if \"_output\" not in os.path.basename(f)\n",
    "]\n",
    "\n",
    "print(\"Num child files:\", len(child_files))\n",
    "child_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cd24e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 2000\n"
     ]
    }
   ],
   "source": [
    "def child_id_from_path(fp):\n",
    "    return int(os.path.basename(fp).replace(\"c_\", \"\").replace(\".csv\", \"\"))\n",
    "\n",
    "def load_child_text(fp):\n",
    "    df = pd.read_csv(fp)\n",
    "\n",
    "    title = str(df.loc[0, \"title\"]) if \"title\" in df.columns else \"\"\n",
    "    content = str(df.loc[0, \"content\"]) if \"content\" in df.columns else \"\"\n",
    "\n",
    "    return (title + \"\\n\" + content).strip()\n",
    "\n",
    "LIMIT = 2000  # increase later\n",
    "corpus_ids = []\n",
    "corpus_texts = []\n",
    "\n",
    "for fp in child_files[:LIMIT]:\n",
    "    text = load_child_text(fp)\n",
    "\n",
    "    if len(text) < 50:   # skip empty rows\n",
    "        continue\n",
    "\n",
    "    corpus_ids.append(str(child_id_from_path(fp)))\n",
    "    corpus_texts.append(text)\n",
    "\n",
    "print(\"Corpus size:\", len(corpus_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eaaee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rank-bm25 sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dc14cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1419170',\n",
       " '1218784',\n",
       " '1343555',\n",
       " '1250273',\n",
       " '1438169',\n",
       " '1352464',\n",
       " '1430086',\n",
       " '771717',\n",
       " '706004',\n",
       " '739545']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\w+\", (text or \"\").lower())\n",
    "\n",
    "# tokenize corpus\n",
    "tokenized_corpus = [tokenize(text) for text in corpus_texts]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "query_tokens = tokenize(parent_text)\n",
    "bm25_scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "# take top 50 candidates\n",
    "top_idx = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:50]\n",
    "bm25_candidates = [corpus_ids[i] for i in top_idx]\n",
    "\n",
    "bm25_candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a6f18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num child docs in corpus: 2000\n",
      "Num texts in corpus: 2000\n",
      "BM25 candidates before cut: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Num child docs in corpus:\", len(corpus_ids))\n",
    "print(\"Num texts in corpus:\", len(corpus_texts))\n",
    "print(\"BM25 candidates before cut:\", len(bm25_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dbe5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 10/10 [00:00<00:00, 40.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# # first version using only 2000 max chars\n",
    "\n",
    "# RERANK_K = 20\n",
    "# bm25_candidates = bm25_candidates[:RERANK_K]\n",
    "\n",
    "# MAX_CHARS = 2000\n",
    "# def cut(t):\n",
    "#     return str(t)[:MAX_CHARS]\n",
    "\n",
    "# reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "# id2text = {doc_id: text for doc_id, text in zip(corpus_ids, corpus_texts)}\n",
    "\n",
    "# pairs = [(cut(parent_text), cut(id2text[doc_id])) for doc_id in bm25_candidates]\n",
    "\n",
    "# ce_scores = reranker.predict(pairs, batch_size=2, show_progress_bar=True)\n",
    "\n",
    "# reranked = sorted(zip(bm25_candidates, ce_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# # reranked[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0038daf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs (chunks): 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 55/55 [00:04<00:00, 13.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# how many candidates to rerank\n",
    "RERANK_K = 20\n",
    "bm25_candidates = bm25_candidates[:RERANK_K]\n",
    "\n",
    "# chunk settings (whole article)\n",
    "CHUNK_SIZE = 1200\n",
    "STRIDE = 900\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "id2text = {doc_id: text for doc_id, text in zip(corpus_ids, corpus_texts)}\n",
    "\n",
    "def chunk_text(text, chunk_size=CHUNK_SIZE, stride=STRIDE):\n",
    "    t = str(text)\n",
    "    if len(t) <= chunk_size:\n",
    "        return [t]\n",
    "    chunks = []\n",
    "    for i in range(0, len(t), stride):\n",
    "        chunks.append(t[i:i+chunk_size])\n",
    "        if i + chunk_size >= len(t):\n",
    "            break\n",
    "    return chunks\n",
    "\n",
    "# build (parent, chunk) pairs\n",
    "pairs = []\n",
    "pair_doc_ids = []\n",
    "\n",
    "for doc_id in bm25_candidates:\n",
    "    child_text = id2text[doc_id]\n",
    "    for ch in chunk_text(child_text):\n",
    "        pairs.append((str(parent_text), ch))\n",
    "        pair_doc_ids.append(doc_id)\n",
    "\n",
    "print(\"Total pairs (chunks):\", len(pairs))\n",
    "\n",
    "# score all chunks\n",
    "chunk_scores = reranker.predict(\n",
    "    pairs,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# keep BEST chunk score per article\n",
    "best_score = {}\n",
    "for doc_id, s in zip(pair_doc_ids, chunk_scores):\n",
    "    s = float(s)\n",
    "    if (doc_id not in best_score) or (s > best_score[doc_id]):\n",
    "        best_score[doc_id] = s\n",
    "\n",
    "# final reranked list (article-level)\n",
    "reranked = sorted(best_score.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad8ba4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_MARGIN = 2.0\n",
    "TOP_K_SHOW = 10\n",
    "\n",
    "topk = reranked[:TOP_K_SHOW]\n",
    "\n",
    "if len(topk) >= 2:\n",
    "    margin = float(topk[0][1] - topk[1][1])\n",
    "    decision = \"AUTO_POSITIVE\" if margin >= AUTO_MARGIN else \"REVIEW\"\n",
    "else:\n",
    "    margin = None\n",
    "    decision = \"REVIEW\"\n",
    "\n",
    "rows = []\n",
    "for rank, (child_id, score) in enumerate(topk, start=1):\n",
    "    rows.append({\n",
    "        \"parent_id\": int(parent_id),\n",
    "        \"child_id\": int(child_id),\n",
    "        \"rank\": rank,\n",
    "        \"score\": float(score),\n",
    "        \"margin_top1_top2\": margin if rank == 1 else \"\",\n",
    "        \"decision\": decision if rank == 1 else \"IGNORE\"\n",
    "    })\n",
    "\n",
    "model_c_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1010182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model_c_parent_674230_margin_2.0.csv\n"
     ]
    }
   ],
   "source": [
    "out_file = f\"model_c_parent_{parent_id}_margin_{AUTO_MARGIN}.csv\"\n",
    "model_c_df.to_csv(out_file, index=False)\n",
    "\n",
    "print(\"Saved\", out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63105295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc_id in bm25_candidates[:3]:\n",
    "#     txt = id2text[str(doc_id)]\n",
    "#     print(\"----\", doc_id, \"len=\", len(txt))\n",
    "#     print(txt[:300])\n",
    "\n",
    "# df = pd.read_csv(child_files[0])\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44e70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
